{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# useful info\n",
    "Before discussing the lagrangian method we need some informations:\n",
    "\n",
    "- A LEVEL CURVE(SET) of a function f(x,y) is the curve of points (x,y) where f(x,y) is some CONSTANT VALUE. ( a function can be visually represented by many level curves).\n",
    "\n",
    "\n",
    "- THE GRADIENT of f IS ORTHOGONAL TO THE LEVEL CURVE of f in any point. To understant why: The gradient shows the direction of maximum variation. Along the level curve the variation is zero. So the gradient must have no components along the curve in each point. To have more familiarity with it, play with this: https://www.geogebra.org/m/iTZ190Cj\n",
    "\n",
    "\n",
    "- CONSTRAINED PROBLEMS CAN HAVE TWO KINDS OF CONSTRAINTS:\n",
    "   - EQUALITIES of the form $ g(\\vec{x}) =0$ (or same thing like  $g(\\vec{x}) =c$)\n",
    "   - INEQUALITIES of the form $ g(\\vec{x}) \\leq 0$ or $ g(\\vec{x}) \\geq 0$\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langranian method for equality constraints optimization\n",
    "It is based on the idea here well explained: https://www.youtube.com/watch?v=aep6lwPqm6I&list=PLCg2-CTYVrQvNGLbd-FN70UxWZSeKP4wV&index=2\n",
    "\n",
    "IT REGARDS ONLY THE OPTIMIZATION PROBLEMS WITH EQUALITY CONSTRAINTS.\n",
    "The idea of the method is that the NECESSARY CONDITION for point of maxima or minima is this:\n",
    "\n",
    "are the points in which the LEVEL CURVE of the function f is tangent to the constraint function g. \n",
    "\n",
    "So how can we check this condition? Well, if the level curves are tangent (the equality constraint is indeed represantable as a level curve if you think about it), and we know that the gradients are orthogonal to the level curves, then THE GRADIENT OF f AND THE GRADIENT OF g MUST BE PARALLEL : $$ \\nabla f(\\vec{x_{critical}}) = \\lambda \\nabla g(\\vec{x_{critical}}) $$\n",
    "$\\lambda$ is called lagrange multiplier.\n",
    "\n",
    "Why don't we simply substitute the variables exploiting the equality constraints? because if the constraints are many and complex it is not trivial to do it. Instead thanks to the Lagrangian method we can transform the problem from constrained to unconstrained:\n",
    "The condition $ \\nabla f(\\vec{x_{critical}}) = \\lambda \\nabla g(\\vec{x_{critical}}) $ can be reformulated in a more useful way:\n",
    "We say that the constrained original problem, of looking for the extrema of f given the constraints g, becomes an unconstrained problem where the function to optimize is \"THE LAGRANGIAN\" function:\n",
    "$$ {\\displaystyle {\\mathcal {L}}(\\vec{x},\\lambda )=f(\\vec{x})  +  \\lambda g(\\vec{x})} $$\n",
    "Indeed by looking for the critical points of L we're looking exactly for what we wanted:\n",
    "$${\\displaystyle \\nabla _{\\vec{x},\\lambda }{\\mathcal {L}}(\\vec{x},\\lambda )=0\\iff {\\begin{cases}\\nabla _{\\vec{x}}f(\\vec{x})=\\lambda \\,\\nabla _{\\vec{x}}g(\\vec{x})\\\\g(\\vec{x})=0\\end{cases}}}$$\n",
    "\n",
    "(the first condition comes from computing  ${\\displaystyle \\nabla _{\\vec{x}}{\\mathcal {L}}(\\vec{x},\\lambda )=0}$, the second one from ${\\displaystyle \\nabla _{\\lambda}{\\mathcal {L}}(\\vec{x}, \\lambda)=0} $\n",
    "SO YOU MUST TREAT THE LAGRANGIAN FUNCTION EXACTLY AS IF IT IS A FUNCTION TO OPTIMIZE, WITH NO CONSTRAINTS.\n",
    "The generalization of it for the multivariate case with many EQUALITY constraints is trivial:\n",
    "$$ {\\displaystyle {\\mathcal {L}}\\left(x_{1},\\ldots ,x_{n},\\lambda _{1},\\ldots ,\\lambda _{M}\\right)=f\\left(x_{1},\\ldots ,x_{n}\\right)   +   \\sum \\limits _{k=1}^{M}{\\lambda _{k}g_{k}\\left(x_{1},\\ldots ,x_{n}\\right)}} $$\n",
    "This can be expressed more elegantly removing the sum, using the dot product between a vector containing the multipliers and a vector containing the constraints:\n",
    "$${\\displaystyle L(\\mathbf {x} ,\\mathbf {\\mu } ,\\mathbf {\\lambda } )=f(\\mathbf {x} )   +   \\mathbf {\\lambda } ^{\\top }\\mathbf {g} (\\mathbf {x} )}$$\n",
    "\n",
    "Note:\n",
    "- you could find the same expression with the \"-\" instead than the \"+\" before lambda. It doesn't change, simply lambda will change sign. This is instead important when you treat also inequalities.\n",
    "- You add as many variables as are the equality constraints.\n",
    "- once the critical points of the lagrangian function have been found, how can you understand if those are max or min or saddle point for the original function f? Well you know that the max or min is NECESSARLY between them, so you can evaluate the function in all those points and if you're looking for the minimum -> it's where f has the minimum value wrt those points.\n",
    "\n",
    "- THERE'S A PROBLEM: THE CRITICAL POINTS OF f with the constraint g ARE GIVEN BY THE POINTS IN WHICH THE GRADIENT OF THE LAGRANGIAN IS ZERO, SO BY THE CRITICAL POINTS OF THE LAGRANGIAN FUNCTION. BUT: IF I APPLY NUMERICAL METHODS (like gradient descent etc.) THEN I'LL probably GET ONLY THE MAXIMUM OR MINUMUM OF THE LAGRANGIAN FUNCTION, BUT PROBABLY I'LL MISS THE SADDLE POINTS (is possible to find them but more rare). So there are two solutions:\n",
    "   - use an iterative method which is designed to find critical points (not only max or min)\n",
    "   - slightly change the problem: USUALLY WE APPLY THE METHOD, LIKE GRADIENT DESCENT, AND WE USE THE GRADIENT MAGNITUDE AS STEPPING RULE. BUT WE CAN DO BETTER IF OUT AIM IS TO FIND ALSO THE SADDLE POINTS: WE APPLY THE GRADIENT DESCENT METHOD TO ANOTHER FUNCTION: THE FUNCTION OF THE MAGNITUDE OF THE GRADIENT. OR EVEN BETTER: TO THE SQUARED MAGNITUDE, IN ORDER TO REMOVE THE SQUARE ROOT.(This is done in the example 4 of wikipedia).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMPLES: https://en.wikipedia.org/wiki/Lagrange_multiplier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KKT : EXTENSION OF THE LAGRANGIAN METHOD, TO DEAL WITH INEQUALITY CONSTRAINTS.\n",
    "\n",
    "It's an extension of the lagrangian method, to deal also with inequality constraints. The reasoning is similar but a little bit more complex. In particular the main difference is that once we build the Lagrangian function, we're interested not in the critical points in general, but in the SADDLE POINTS only. That's why we need some conditions to find such points. The NECESSARY CONDITIONS TO FIND THE SADDLE POINTS OF THE LAGRANGIAN FUNCTION, SO THE EXTREMA OF THE CONSTRAINED ORIGINAL FUNCTION, ARE CALLED KKT CONDITIONS. REMEMBER THAT THE MINIMUM OF THE OBJECTIVE FUNCTION ARE FOUND IN CORRESPONDENCE OF THE SADDLE POINTS OF THE LAGRANGIAN FUNCTION BECAUSE IN THOSE POINTS THE LAGRANGIAN FUNCTION IS MINIMUM WRT THE DECISION VARIABLES AND MAXIMUM WRT THE LAGRANGIAN MULTIPLIERS. WE'LL EXPLOIT THIS TO TALK ABOUT DUALITY IN LINEAR PROGRAMMING.Let's see first how is built the Lagrangian function, then we'll discuss the kkt conditions:\n",
    "\n",
    "Consider the following nonlinear minimization or maximization problem:\n",
    "\n",
    "Optimize $$ {\\displaystyle f(\\mathbf {x} )} $$\n",
    "subject to\n",
    "$${\\displaystyle g_{i}(\\mathbf {x} )\\geq 0,}$$\n",
    "$${\\displaystyle h_{i}(\\mathbf {x} )=0.}$$\n",
    "\n",
    "then the Lagrangian function is:\n",
    "\n",
    "$${\\displaystyle L(\\mathbf {x} ,\\mathbf {\\lambda } ,\\mathbf {\\mu } )=f(\\mathbf {x} )  - \\mathbf {\\lambda } ^{\\top }\\mathbf {g} (\\mathbf {x} ) -  \\mathbf {\\mu } ^{\\top }\\mathbf {h} (\\mathbf {x} )}$$\n",
    "\n",
    "both $\\lambda$ and $\\mu$ are called lagrangian multipliers, but indicated with different simbols depending on if are associated to equality or inequality constraints.\n",
    "\n",
    "the KKT conditions are:\n",
    "- Stationarity (for minimization problems, for maximization change the signs before the sums. The sign of this conditions depend on the use of $\\geq$ or $\\leq$ in the inequality constraints):\n",
    "\n",
    "  $ {\\displaystyle \\nabla f(x^{*}) - \\sum _{i=1}^{m}\\lambda_{i}\\nabla g_{i}(x^{*}) - \\sum _{j=1}^{\\ell }\\mu _{j}\\nabla h_{j}(x^{*})=0}$\n",
    "  \n",
    "- Primal feasibility (all constraints must be satisfied in the critical point):\n",
    "  \n",
    "  ${\\displaystyle g_{i}(x^{*})\\geq 0,{\\text{ for }}i=1,\\ldots ,m}$\n",
    "  \n",
    "  ${\\displaystyle h_{j}(x^{*})=0,{\\text{ for }}j=1,\\ldots ,\\ell \\,\\!}$\n",
    "  \n",
    "\n",
    "- Dual feasibility:\n",
    "\n",
    "  ${\\displaystyle \\lambda _{i}\\geq 0,{\\text{ for }}i=1,\\ldots ,m}$\n",
    "  \n",
    "  \n",
    "- Complementary slackness:\n",
    "\n",
    " ${\\displaystyle \\lambda _{i}g_{i}(x^{*})=0,{\\text{ for }}\\;i=1,\\ldots ,m.}$\n",
    "\n",
    "\n",
    "  \n",
    "  \n",
    "The KKT conditions can also be written in a standard linear programming form:\n",
    "\n",
    "- Stationarity (for minimization problems,  for maximization change the signs before the sums)\n",
    "\n",
    "  $ c - \\mu A - \\lambda = 0 $\n",
    "\n",
    "- Primal feasibility\n",
    "  \n",
    "  $ Ax = b $\n",
    "  $ x \\geq 0 $  \n",
    "\n",
    "- Dual feasibility\n",
    "\n",
    "  $ \\lambda \\geq 0 $  (the case $\\lambda=0$ is when the inequality constraint is \"inactive\", $\\lambda>0$ when the ineq. const. is \"active\").\n",
    "\n",
    "  \n",
    "- Complementary slackness\n",
    "\n",
    "  $ \\lambda x = 0 $\n",
    "  \n",
    "  \n",
    "note:\n",
    "- in the case of equality constraints the sign of preceeding lambda wasn't important, IN THE CASE OF INEQUALITY CONSTRAINTS IT MATTERS! YOU HAVE TO TRANSFORM ALL THE INEQUATIONS IN THE FORM \"GREATER THAN\" AND WRITE THE LAGRANGIAN USING THE MINUS BEFORE LAMBDA AND MU. THIS IS IMPORTANT BECAUSE ONLY IN THIS WAY THE DUAL FEASIBILITY KKT CONDITION IS $ \\lambda \\geq 0 $ (OTHERWISE IT SHOULD BE LESS THAN).\n",
    "\n",
    "- the kkt conditions are first order conditions. They are only NECESSARY conditions.\n",
    "\n",
    "- the last kkt condition is non linear (lambda is a variable, and you're creating a product between variables), so if you apply them to a linear problem it becomes non linear.\n",
    "\n",
    "- there's a useful property which we'll use a lot in linear programming: The Lagrangian function has a maximum where f has a feasible minimum.  (TRUE ONLY IF THE OBJECTIVE FUNCTION AND THE CONSTRAINTS ARE CONVEX)\n",
    "\n",
    "- WE USE THE FIRST KKT CONDITION TO FIND/SEARCH THE CRITICAL POINTS, THEN WE CHECK THE OTHER KKT CONDITIONS to the points found. THIS IS HOW THE SEARCH OF THE CRITICAL POINT OF THE OBJECTIVE FUNCTION USING THE KKT CONDITIONS IS DONE:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LET'S DO THE REASONING WITH ONLY ONE INEQUALITY CONSTRAINT g(x) >= 0.\n",
    "TO UNDERSTAND THE PROCESS WE MUST know that there are two possibilities:\n",
    "    \n",
    "1) ACTIVE CONSTRAINT: The minimum of the function is on the boundary of the constraint, so where g(x)=0. IF THIS IS THE CASE IT PROBABLY IS BECAUSE THE CONSTRAINED SOLUTION IS NOT THE SAME OF THE UNCONSTRAINED PROBLEM (as in the example, where the unconstrained problem solution would have had as solution the global minimum, with the constraint the solution is the green dot). IN THIS CASE we must set $\\lambda \\neq 0$, because as we said the lagrangian function must be different from the objective function. TO BE MORE PRECISE WE'LL HAVE TO CHECK IF THE Dual feasibility CONDITION IS SATISFIED, SO $\\lambda > 0$. (IS IT CALLED ACTIVE CONSTRAINT BECAUSE IF YOU REMOVE IT THE SOLUTION IS DIFFERENT). NOTE THAT THE CONSTRAINT IS ACTIVE OR NOT DEPENDING ALSO ON THE OBJECTIVE FUNCTION. EXAMPLE OF ACTIVE CONSTRAINT:\n",
    "  $g(x) = x-1 >=0$  and $f(x,y) = x^2 + y^2$. \n",
    "\n",
    "<img src=\"active_constraint.png\"  width=30%  height= 30%>\n",
    "    \n",
    "2) INACTIVE CONSTRAINT: The constraint could be useless, because the minimum found using the constraint is the same in the case we solve the unconstrained problem. It could happen because the minimum of the objective function is within the set of points which satisfy the constraint. If the constraint is useless it means that we can set $\\lambda = 0 $.  Example:  As the previous one, but considering the left part of the plane, so the constraint $g(x) =  -x+1 >=0$ \n",
    "\n",
    " \n",
    " \n",
    " \n",
    "The minimum is given by the point which gives you the minimum value of the objective function, among the points found hypotizing both the constraint active and inactive.\n",
    "\n",
    "\n",
    "HOW DO I KNOW IF THE CONSTRAINT IS ACTIVE OR NOT? YOU DON'T. YOU MUST TRY BOTH CASES. First you assume $\\lambda = 0$ and the constraint = 0 (so you remove it). Then you consider the other case: you consider the constraint g(x) >=0, and impose that $\\lambda >0 $. FOR EACH CASE YOU COULD FIND MANY POINTS WHICH SATISFY THE CONDITIONS. So how do you estabilish which is the minimum? simple: compute the values of the objective function in each of these points.\n",
    "\n",
    "# Example 1\n",
    "\n",
    "objective function: $f(x) = x^2$\n",
    "\n",
    "inequality constraint: g(x) = x-2 <= 0\n",
    "\n",
    "- assuming the constraint ACTIVE:\n",
    "\n",
    "  Lagrangian function = $L = x^2  - \\lambda (x-2)  = x^2 - \\lambda x + 2\\lambda$\n",
    "\n",
    "   gradient of the lagrangian function = $ \\nabla L = ( 2x - \\lambda, -x + 2 ) = 0 $ only in this point:  x=2, where lambda = 4.  \n",
    "   Since $\\lambda \\neq 0$ as we want in the case of Active constraint, then x=2 is a feasible solution. The value f(2) = 4, so we'll compare this value with the points obtained considering the constraint inactive.\n",
    "\n",
    "\n",
    "\n",
    "- assuming the constraint INACTIVE:\n",
    "\n",
    "  In this case it was the only constraint, so remove it is exactly as cmputing the global minimum of the unconstraint function, so we don't have to write the lagrangian (indeed the lagrangian with $\\lambda = 0$ is the objective function). So we compute this:\n",
    "\n",
    "  $ \\nabla f  = 2x = 0 $ when x= 0. In that point we have f(0) = 0.\n",
    "\n",
    "Comparing the points obtained in the two cases we see that the minimum point is x=0.\n",
    "\n",
    "\n",
    "# Example 2:\n",
    "$f(x,y) = x^2 + y^2$ \n",
    "$g(x,y) = 2x + y \\leq 2$\n",
    "\n",
    "The first thing to do is to transform the inequality constraint in the standard form, to don't get confused with signs or other things. so:  $g(x,y) = -2x - y +2 \\geq 0$.\n",
    "\n",
    "- assuming g(x,y) Active:\n",
    "  We must compute the lagrangian. Then equal the gradient of the lagrangian to zero, then check if the resulting point(s) satisfy the condition $\\lambda >= 0 $.\n",
    "  $ L(x,y,\\lambda) = x^2 + y^2 - \\lambda ( - 2x - y + 2) $\n",
    "  $ \\nabla L(x,y,\\lambda) = (2x-2\\lambda, 2y - \\lambda, 2x + y - 2) = 0 $ when $x=\\lambda$, $y=\\frac{\\lambda}{2}$ $\\lambda = \\frac{-6}{5}$\n",
    "  There's a problem: $\\lambda \\leq 0$ but the KKT condition says that the necessary condition to be a minimum is that $\\lambda \\geq 0$. So this point must be discarded.\n",
    "\n",
    "\n",
    "- assuming g(x,y) Inactive:\n",
    "  We must assume that $\\lambda =0$. So also in this case the lagrangian function corresponds to the objective funtion. So we simply must look for the points in which the gradient of the function is equal to zero. Doing the computation we find (0,0). Which is also the solution of the constrained problem in this case.\n",
    "  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More:\n",
    "\n",
    "- Look for more examples to see what happens if you must deal with more constraints together.\n",
    "\n",
    "- SVM is based on the solution of a non linear constrained problem to find the line with the maximum margin. This is solved with the Lagrance method (using also KKT). That's why SVM is so important: it is an OPTIMAL binary classifier, and the optimality is based on the strong mathematical theory of lagrange.\n",
    "\n",
    "- there's a useful property which we'll use a lot in linear programming: The Lagrangian function has a maximum wrt to the lagrangian multipliers where f has a feasible minimum.  (TRUE ONLY IF THE OBJECTIVE FUNCTION AND THE CONSTRAINTS ARE CONVEX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
